{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"train.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"titanic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SCOPE\n",
    "Here I try to get the requests with spark methods and sql queries. The requests according to `titanic_simple_analysis.py` file:\n",
    "1. Schema of the dataset.\n",
    "2. Gender distribution of cleaned dataset.\n",
    "3. City distribution of cleaned dataset.\n",
    "4. Average of descriptive stats.\n",
    "5. Describe of descriptive stats.\n",
    "6. Median of descriptive stats.\n",
    "7. Price averages according to classes.\n",
    "8. Association between price and age.\n",
    "9. Family size table.\n",
    "10. Age group table. <br> <br> <br>\n",
    "***\n",
    "##### TODO\n",
    "- [x] Schema of the dataset.\n",
    "- [x] Gender distribution of cleaned dataset.\n",
    "- [x] City distribution of cleaned dataset.\n",
    "- [x] Average of descriptive stats.\n",
    "- [x] Describe of descriptive stats.\n",
    "- [ ] Median of descriptive stats.\n",
    "- [x] Price averages according to classes.\n",
    "- [ ] Association between price and age.\n",
    "- [ ] Family size table.\n",
    "- [ ] Age group table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+\n",
      "|   col_name|data_type|comment|\n",
      "+-----------+---------+-------+\n",
      "|PassengerId|      int|   NULL|\n",
      "|   Survived|      int|   NULL|\n",
      "|     Pclass|      int|   NULL|\n",
      "|       Name|   string|   NULL|\n",
      "|        Sex|   string|   NULL|\n",
      "|        Age|   double|   NULL|\n",
      "|      SibSp|      int|   NULL|\n",
      "|      Parch|      int|   NULL|\n",
      "|     Ticket|   string|   NULL|\n",
      "|       Fare|   double|   NULL|\n",
      "|      Cabin|   string|   NULL|\n",
      "|   Embarked|   string|   NULL|\n",
      "+-----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE titanic;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+--------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|     Ticket|    Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+--------+-----------+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|   PC 17599| 71.2833|        C85|       C|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|     113803|    53.1|       C123|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|      17463| 51.8625|        E46|       S|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|    PP 9549|    16.7|         G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|     113783|   26.55|       C103|       S|\n",
      "|         22|       1|     2|Beesley, Mr. Lawr...|  male|34.0|    0|    0|     248698|    13.0|        D56|       S|\n",
      "|         24|       1|     1|Sloper, Mr. Willi...|  male|28.0|    0|    0|     113788|    35.5|         A6|       S|\n",
      "|         28|       0|     1|Fortune, Mr. Char...|  male|19.0|    3|    2|      19950|   263.0|C23 C25 C27|       S|\n",
      "|         53|       1|     1|Harper, Mrs. Henr...|female|49.0|    1|    0|   PC 17572| 76.7292|        D33|       C|\n",
      "|         55|       0|     1|Ostby, Mr. Engelh...|  male|65.0|    0|    1|     113509| 61.9792|        B30|       C|\n",
      "|         63|       0|     1|Harris, Mr. Henry...|  male|45.0|    1|    0|      36973|  83.475|        C83|       S|\n",
      "|         67|       1|     2|Nye, Mrs. (Elizab...|female|29.0|    0|    0| C.A. 29395|    10.5|        F33|       S|\n",
      "|         76|       0|     3|Moen, Mr. Sigurd ...|  male|25.0|    0|    0|     348123|    7.65|      F G73|       S|\n",
      "|         89|       1|     1|Fortune, Miss. Ma...|female|23.0|    3|    2|      19950|   263.0|C23 C25 C27|       S|\n",
      "|         93|       0|     1|Chaffee, Mr. Herb...|  male|46.0|    1|    0|W.E.P. 5734|  61.175|        E31|       S|\n",
      "|         97|       0|     1|Goldschmidt, Mr. ...|  male|71.0|    0|    0|   PC 17754| 34.6542|         A5|       C|\n",
      "|         98|       1|     1|Greenfield, Mr. W...|  male|23.0|    0|    1|   PC 17759| 63.3583|    D10 D12|       C|\n",
      "|        103|       0|     1|White, Mr. Richar...|  male|21.0|    0|    1|      35281| 77.2875|        D26|       S|\n",
      "|        111|       0|     1|Porter, Mr. Walte...|  male|47.0|    0|    0|     110465|    52.0|       C110|       S|\n",
      "|        119|       0|     1|Baxter, Mr. Quigg...|  male|24.0|    0|    1|   PC 17558|247.5208|    B58 B60|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+--------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = df.na.drop()\n",
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+--------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|     Ticket|    Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+--------+-----------+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|   PC 17599| 71.2833|        C85|       C|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|     113803|    53.1|       C123|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|      17463| 51.8625|        E46|       S|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|    PP 9549|    16.7|         G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|     113783|   26.55|       C103|       S|\n",
      "|         22|       1|     2|Beesley, Mr. Lawr...|  male|34.0|    0|    0|     248698|    13.0|        D56|       S|\n",
      "|         24|       1|     1|Sloper, Mr. Willi...|  male|28.0|    0|    0|     113788|    35.5|         A6|       S|\n",
      "|         28|       0|     1|Fortune, Mr. Char...|  male|19.0|    3|    2|      19950|   263.0|C23 C25 C27|       S|\n",
      "|         53|       1|     1|Harper, Mrs. Henr...|female|49.0|    1|    0|   PC 17572| 76.7292|        D33|       C|\n",
      "|         55|       0|     1|Ostby, Mr. Engelh...|  male|65.0|    0|    1|     113509| 61.9792|        B30|       C|\n",
      "|         63|       0|     1|Harris, Mr. Henry...|  male|45.0|    1|    0|      36973|  83.475|        C83|       S|\n",
      "|         67|       1|     2|Nye, Mrs. (Elizab...|female|29.0|    0|    0| C.A. 29395|    10.5|        F33|       S|\n",
      "|         76|       0|     3|Moen, Mr. Sigurd ...|  male|25.0|    0|    0|     348123|    7.65|      F G73|       S|\n",
      "|         89|       1|     1|Fortune, Miss. Ma...|female|23.0|    3|    2|      19950|   263.0|C23 C25 C27|       S|\n",
      "|         93|       0|     1|Chaffee, Mr. Herb...|  male|46.0|    1|    0|W.E.P. 5734|  61.175|        E31|       S|\n",
      "|         97|       0|     1|Goldschmidt, Mr. ...|  male|71.0|    0|    0|   PC 17754| 34.6542|         A5|       C|\n",
      "|         98|       1|     1|Greenfield, Mr. W...|  male|23.0|    0|    1|   PC 17759| 63.3583|    D10 D12|       C|\n",
      "|        103|       0|     1|White, Mr. Richar...|  male|21.0|    0|    1|      35281| 77.2875|        D26|       S|\n",
      "|        111|       0|     1|Porter, Mr. Walte...|  male|47.0|    0|    0|     110465|    52.0|       C110|       S|\n",
      "|        119|       0|     1|Baxter, Mr. Quigg...|  male|24.0|    0|    1|   PC 17558|247.5208|    B58 B60|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+--------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM titanic\n",
    "    WHERE PassengerId IS NOT NULL\n",
    "    AND Survived IS NOT NULL\n",
    "    AND Pclass IS NOT NULL\n",
    "    AND Name IS NOT NULL\n",
    "    AND Sex IS NOT NULL\n",
    "    AND Age IS NOT NULL\n",
    "    AND SibSp IS NOT NULL\n",
    "    AND Parch IS NOT NULL\n",
    "    AND Ticket IS NOT NULL\n",
    "    AND Fare IS NOT NULL\n",
    "    AND Cabin IS NOT NULL\n",
    "    AND Embarked IS NOT NULL\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|   88|\n",
      "|  male|   95|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.groupBy(\"Sex\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|count(Sex)|\n",
      "+----------+\n",
      "|        88|\n",
      "|        95|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(Sex) FROM titanic\n",
    "    WHERE PassengerId IS NOT NULL\n",
    "    AND Survived IS NOT NULL\n",
    "    AND Pclass IS NOT NULL\n",
    "    AND Name IS NOT NULL\n",
    "    AND Sex IS NOT NULL\n",
    "    AND Age IS NOT NULL\n",
    "    AND SibSp IS NOT NULL\n",
    "    AND Parch IS NOT NULL\n",
    "    AND Ticket IS NOT NULL\n",
    "    AND Fare IS NOT NULL\n",
    "    AND Cabin IS NOT NULL\n",
    "    AND Embarked IS NOT NULL\n",
    "    GROUP BY Sex;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|    2|\n",
      "|       C|   65|\n",
      "|       S|  116|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.groupBy(\"Embarked\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(Embarked)|\n",
      "+---------------+\n",
      "|              2|\n",
      "|             65|\n",
      "|            116|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(Embarked) FROM titanic\n",
    "    WHERE PassengerId IS NOT NULL\n",
    "    AND Survived IS NOT NULL\n",
    "    AND Pclass IS NOT NULL\n",
    "    AND Name IS NOT NULL\n",
    "    AND Sex IS NOT NULL\n",
    "    AND Age IS NOT NULL\n",
    "    AND SibSp IS NOT NULL\n",
    "    AND Parch IS NOT NULL\n",
    "    AND Ticket IS NOT NULL\n",
    "    AND Fare IS NOT NULL\n",
    "    AND Cabin IS NOT NULL\n",
    "    AND Embarked IS NOT NULL\n",
    "    GROUP BY Embarked;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descriptive stats\n",
    "1. Pclass\n",
    "2. Age\n",
    "3. SibSp\n",
    "4. Parch\n",
    "5. Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+------------------+-------------------+----------------+\n",
      "|      avg(Pclass)|         avg(Age)|        avg(SibSp)|         avg(Parch)|       avg(Fare)|\n",
      "+-----------------+-----------------+------------------+-------------------+----------------+\n",
      "|2.308641975308642|29.69911764705882|0.5230078563411896|0.38159371492704824|32.2042079685746|\n",
      "+-----------------+-----------------+------------------+-------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").groupBy().avg(\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+------------------+-------------------+----------------+\n",
      "|      avg(Pclass)|         avg(Age)|        avg(SibSp)|         avg(Parch)|       avg(Fare)|\n",
      "+-----------------+-----------------+------------------+-------------------+----------------+\n",
      "|2.308641975308642|29.69911764705882|0.5230078563411896|0.38159371492704824|32.2042079685746|\n",
      "+-----------------+-----------------+------------------+-------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\" \n",
    "    SELECT AVG(Pclass), AVG(Age), AVG(SibSp), AVG(Parch), AVG(Fare) FROM titanic;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-------------------+-----------------+\n",
      "|summary|            Pclass|               Age|             SibSp|              Parch|             Fare|\n",
      "+-------+------------------+------------------+------------------+-------------------+-----------------+\n",
      "|  count|               891|               714|               891|                891|              891|\n",
      "|   mean| 2.308641975308642| 29.69911764705882|0.5230078563411896|0.38159371492704824| 32.2042079685746|\n",
      "| stddev|0.8360712409770491|14.526497332334035|1.1027434322934315| 0.8060572211299488|49.69342859718089|\n",
      "|    min|                 1|              0.42|                 0|                  0|              0.0|\n",
      "|    max|                 3|              80.0|                 8|                  6|         512.3292|\n",
      "+-------+------------------+------------------+------------------+-------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 16:05:18 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "df.describe(\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------------------+------------------+----+--------+-------+\n",
      "|Pclass|count|               mean|            stddev| min|     max| median|\n",
      "+------+-----+-------------------+------------------+----+--------+-------+\n",
      "|Pclass|  891|  2.308641975308642|0.8360712409770491| 1.0|     3.0|    3.0|\n",
      "|   Age|  714|  29.69911764705882|14.526497332334035|0.42|    80.0|   28.0|\n",
      "| SibSp|  891| 0.5230078563411896|1.1027434322934315| 0.0|     8.0|    0.0|\n",
      "| Parch|  891|0.38159371492704824|0.8060572211299488| 0.0|     6.0|    0.0|\n",
      "|  Fare|  891|   32.2042079685746| 49.69342859718089| 0.0|512.3292|14.4542|\n",
      "+------+-----+-------------------+------------------+----+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        'Pclass' AS Pclass,\n",
    "        COUNT(Pclass) AS count,\n",
    "        AVG(Pclass) AS mean,\n",
    "        STDDEV(Pclass) AS stddev,\n",
    "        MIN(Pclass) AS min,\n",
    "        MAX(Pclass) AS max,\n",
    "        PERCENTILE_APPROX(Pclass, 0.5) AS median\n",
    "    FROM titanic\n",
    "    UNION\n",
    "    SELECT\n",
    "        'Age' AS Age,\n",
    "        COUNT(Age) AS count,\n",
    "        AVG(Age) AS mean,\n",
    "        STDDEV(Age) AS stddev,\n",
    "        MIN(Age) AS min,\n",
    "        MAX(Age) AS max,\n",
    "        PERCENTILE_APPROX(Age, 0.5) AS median\n",
    "    FROM titanic\n",
    "    UNION\n",
    "    SELECT\n",
    "        'SibSp' AS SibSp,\n",
    "        COUNT(SibSp) AS count,\n",
    "        AVG(SibSp) AS mean,\n",
    "        STDDEV(SibSp) AS stddev,\n",
    "        MIN(SibSp) AS min,\n",
    "        MAX(SibSp) AS max,\n",
    "        PERCENTILE_APPROX(SibSp, 0.5) AS median\n",
    "    FROM titanic\n",
    "    UNION\n",
    "    SELECT\n",
    "        'Parch' AS Parch,\n",
    "        COUNT(Parch) AS count,\n",
    "        AVG(Parch) AS mean,\n",
    "        STDDEV(Parch) AS stddev,\n",
    "        MIN(Parch) AS min,\n",
    "        MAX(Parch) AS max,\n",
    "        PERCENTILE_APPROX(Parch, 0.5) AS median\n",
    "    FROM titanic\n",
    "    UNION\n",
    "    SELECT\n",
    "        'Fare' AS Fare,\n",
    "        COUNT(Fare) AS count,\n",
    "        AVG(Fare) AS mean,\n",
    "        STDDEV(Fare) AS stddev,\n",
    "        MIN(Fare) AS min,\n",
    "        MAX(Fare) AS max,\n",
    "        PERCENTILE_APPROX(Fare, 0.5) AS median\n",
    "    FROM titanic;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Pclass|         avg(Fare)|\n",
      "+------+------------------+\n",
      "|     1| 84.15468749999992|\n",
      "|     2| 20.66218315217391|\n",
      "|     3|13.675550101832997|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Pclass\", \"Fare\").groupBy(\"Pclass\").avg(\"Fare\").orderBy(\"Pclass\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Pclass|         avg(Fare)|\n",
      "+------+------------------+\n",
      "|     1| 84.15468749999992|\n",
      "|     2| 20.66218315217391|\n",
      "|     3|13.675550101832997|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT Pclass, AVG(Fare) FROM titanic\n",
    "    GROUP BY Pclass ORDER BY Pclass;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|Age Range|      Fare Average|\n",
      "+---------+------------------+\n",
      "|     0-10|30.434439062500008|\n",
      "|    10-20|  29.4696247863248|\n",
      "|    20-30|  27.1016648979592|\n",
      "|    30-40|40.141317777777786|\n",
      "|    40-50| 40.63093636363638|\n",
      "|    50-60| 48.47692307692308|\n",
      "|    60-70|47.642061904761896|\n",
      "|    70-80|30.169057142857145|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "price_age_df = df.filter(df.Fare.isNotNull())\n",
    "p1 = price_age_df.filter((df.Age >= 0) & (df.Age <= 10)).agg(f.avg(\"Fare\").alias(\"0-10\"))\n",
    "p2 = price_age_df.filter((df.Age >= 10) & (df.Age <= 20)).agg(f.avg(\"Fare\").alias(\"10-20\"))\n",
    "p3 = price_age_df.filter((df.Age >= 20) & (df.Age <= 30)).agg(f.avg(\"Fare\").alias(\"20-30\"))\n",
    "p4 = price_age_df.filter((df.Age >= 30) & (df.Age <= 40)).agg(f.avg(\"Fare\").alias(\"30-40\"))\n",
    "p5 = price_age_df.filter((df.Age >= 40) & (df.Age <= 50)).agg(f.avg(\"Fare\").alias(\"40-50\"))\n",
    "p6 = price_age_df.filter((df.Age >= 50) & (df.Age <= 60)).agg(f.avg(\"Fare\").alias(\"50-60\"))\n",
    "p7 = price_age_df.filter((df.Age >= 60) & (df.Age <= 70)).agg(f.avg(\"Fare\").alias(\"60-70\"))\n",
    "p8 = price_age_df.filter((df.Age >= 70) & (df.Age <= 80)).agg(f.avg(\"Fare\").alias(\"70-80\"))\n",
    "columns = [\"Age Range\",\"Fare Average\"]\n",
    "datas = [\n",
    "    (\"0-10\", p1.collect()[0][0]),\n",
    "    (\"10-20\", p2.collect()[0][0]),\n",
    "    (\"20-30\", p3.collect()[0][0]),\n",
    "    (\"30-40\", p4.collect()[0][0]),\n",
    "    (\"40-50\", p5.collect()[0][0]),\n",
    "    (\"50-60\", p6.collect()[0][0]),\n",
    "    (\"60-70\", p7.collect()[0][0]),\n",
    "    (\"70-80\", p8.collect()[0][0])\n",
    "]\n",
    "new_df = spark.createDataFrame(datas, columns)\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|       avg(Fare)|\n",
      "+----------------+\n",
      "|32.2042079685746|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT AVG(Fare) FROM titanic;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
