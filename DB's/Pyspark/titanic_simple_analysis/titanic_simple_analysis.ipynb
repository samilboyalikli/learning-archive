{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"train.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"titanic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SCOPE\n",
    "Here I try to get the requests with spark methods and sql queries. The requests according to `titanic_simple_analysis.py` file:\n",
    "1. Schema of the dataset.\n",
    "2. Gender distribution of cleaned dataset.\n",
    "3. City distribution of cleaned dataset.\n",
    "4. Average of descriptive stats.\n",
    "5. Describe of descriptive stats.\n",
    "6. Median of descriptive stats.\n",
    "7. Price averages according to classes.\n",
    "8. Association between price and age.\n",
    "9. Family size table.\n",
    "10. Age group table. <br> <br> <br>\n",
    "***\n",
    "##### TODO\n",
    "- [x] Schema of the dataset.\n",
    "- [x] Gender distribution of cleaned dataset.\n",
    "- [x] City distribution of cleaned dataset.\n",
    "- [x] Average of descriptive stats.\n",
    "- [x] Describe of descriptive stats.\n",
    "- [x] Median of descriptive stats.\n",
    "- [x] Price averages according to classes.\n",
    "- [x] Association between price and age.\n",
    "- [x] Family size table.\n",
    "- [x] Age group table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+\n",
      "|   col_name|data_type|comment|\n",
      "+-----------+---------+-------+\n",
      "|PassengerId|      int|   NULL|\n",
      "|   Survived|      int|   NULL|\n",
      "|     Pclass|      int|   NULL|\n",
      "|       Name|   string|   NULL|\n",
      "|        Sex|   string|   NULL|\n",
      "|        Age|   double|   NULL|\n",
      "|      SibSp|      int|   NULL|\n",
      "|      Parch|      int|   NULL|\n",
      "|     Ticket|   string|   NULL|\n",
      "|       Fare|   double|   NULL|\n",
      "|      Cabin|   string|   NULL|\n",
      "|   Embarked|   string|   NULL|\n",
      "+-----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE titanic;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+--------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|     Ticket|    Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+--------+-----------+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|   PC 17599| 71.2833|        C85|       C|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|     113803|    53.1|       C123|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|      17463| 51.8625|        E46|       S|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|    PP 9549|    16.7|         G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|     113783|   26.55|       C103|       S|\n",
      "|         22|       1|     2|Beesley, Mr. Lawr...|  male|34.0|    0|    0|     248698|    13.0|        D56|       S|\n",
      "|         24|       1|     1|Sloper, Mr. Willi...|  male|28.0|    0|    0|     113788|    35.5|         A6|       S|\n",
      "|         28|       0|     1|Fortune, Mr. Char...|  male|19.0|    3|    2|      19950|   263.0|C23 C25 C27|       S|\n",
      "|         53|       1|     1|Harper, Mrs. Henr...|female|49.0|    1|    0|   PC 17572| 76.7292|        D33|       C|\n",
      "|         55|       0|     1|Ostby, Mr. Engelh...|  male|65.0|    0|    1|     113509| 61.9792|        B30|       C|\n",
      "|         63|       0|     1|Harris, Mr. Henry...|  male|45.0|    1|    0|      36973|  83.475|        C83|       S|\n",
      "|         67|       1|     2|Nye, Mrs. (Elizab...|female|29.0|    0|    0| C.A. 29395|    10.5|        F33|       S|\n",
      "|         76|       0|     3|Moen, Mr. Sigurd ...|  male|25.0|    0|    0|     348123|    7.65|      F G73|       S|\n",
      "|         89|       1|     1|Fortune, Miss. Ma...|female|23.0|    3|    2|      19950|   263.0|C23 C25 C27|       S|\n",
      "|         93|       0|     1|Chaffee, Mr. Herb...|  male|46.0|    1|    0|W.E.P. 5734|  61.175|        E31|       S|\n",
      "|         97|       0|     1|Goldschmidt, Mr. ...|  male|71.0|    0|    0|   PC 17754| 34.6542|         A5|       C|\n",
      "|         98|       1|     1|Greenfield, Mr. W...|  male|23.0|    0|    1|   PC 17759| 63.3583|    D10 D12|       C|\n",
      "|        103|       0|     1|White, Mr. Richar...|  male|21.0|    0|    1|      35281| 77.2875|        D26|       S|\n",
      "|        111|       0|     1|Porter, Mr. Walte...|  male|47.0|    0|    0|     110465|    52.0|       C110|       S|\n",
      "|        119|       0|     1|Baxter, Mr. Quigg...|  male|24.0|    0|    1|   PC 17558|247.5208|    B58 B60|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+--------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = df.na.drop()\n",
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+--------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|     Ticket|    Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+--------+-----------+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|   PC 17599| 71.2833|        C85|       C|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|     113803|    53.1|       C123|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|      17463| 51.8625|        E46|       S|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|    PP 9549|    16.7|         G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|     113783|   26.55|       C103|       S|\n",
      "|         22|       1|     2|Beesley, Mr. Lawr...|  male|34.0|    0|    0|     248698|    13.0|        D56|       S|\n",
      "|         24|       1|     1|Sloper, Mr. Willi...|  male|28.0|    0|    0|     113788|    35.5|         A6|       S|\n",
      "|         28|       0|     1|Fortune, Mr. Char...|  male|19.0|    3|    2|      19950|   263.0|C23 C25 C27|       S|\n",
      "|         53|       1|     1|Harper, Mrs. Henr...|female|49.0|    1|    0|   PC 17572| 76.7292|        D33|       C|\n",
      "|         55|       0|     1|Ostby, Mr. Engelh...|  male|65.0|    0|    1|     113509| 61.9792|        B30|       C|\n",
      "|         63|       0|     1|Harris, Mr. Henry...|  male|45.0|    1|    0|      36973|  83.475|        C83|       S|\n",
      "|         67|       1|     2|Nye, Mrs. (Elizab...|female|29.0|    0|    0| C.A. 29395|    10.5|        F33|       S|\n",
      "|         76|       0|     3|Moen, Mr. Sigurd ...|  male|25.0|    0|    0|     348123|    7.65|      F G73|       S|\n",
      "|         89|       1|     1|Fortune, Miss. Ma...|female|23.0|    3|    2|      19950|   263.0|C23 C25 C27|       S|\n",
      "|         93|       0|     1|Chaffee, Mr. Herb...|  male|46.0|    1|    0|W.E.P. 5734|  61.175|        E31|       S|\n",
      "|         97|       0|     1|Goldschmidt, Mr. ...|  male|71.0|    0|    0|   PC 17754| 34.6542|         A5|       C|\n",
      "|         98|       1|     1|Greenfield, Mr. W...|  male|23.0|    0|    1|   PC 17759| 63.3583|    D10 D12|       C|\n",
      "|        103|       0|     1|White, Mr. Richar...|  male|21.0|    0|    1|      35281| 77.2875|        D26|       S|\n",
      "|        111|       0|     1|Porter, Mr. Walte...|  male|47.0|    0|    0|     110465|    52.0|       C110|       S|\n",
      "|        119|       0|     1|Baxter, Mr. Quigg...|  male|24.0|    0|    1|   PC 17558|247.5208|    B58 B60|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+--------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM titanic\n",
    "    WHERE PassengerId IS NOT NULL\n",
    "    AND Survived IS NOT NULL\n",
    "    AND Pclass IS NOT NULL\n",
    "    AND Name IS NOT NULL\n",
    "    AND Sex IS NOT NULL\n",
    "    AND Age IS NOT NULL\n",
    "    AND SibSp IS NOT NULL\n",
    "    AND Parch IS NOT NULL\n",
    "    AND Ticket IS NOT NULL\n",
    "    AND Fare IS NOT NULL\n",
    "    AND Cabin IS NOT NULL\n",
    "    AND Embarked IS NOT NULL\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|   88|\n",
      "|  male|   95|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.groupBy(\"Sex\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|count(Sex)|\n",
      "+----------+\n",
      "|        88|\n",
      "|        95|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(Sex) FROM titanic\n",
    "    WHERE PassengerId IS NOT NULL\n",
    "    AND Survived IS NOT NULL\n",
    "    AND Pclass IS NOT NULL\n",
    "    AND Name IS NOT NULL\n",
    "    AND Sex IS NOT NULL\n",
    "    AND Age IS NOT NULL\n",
    "    AND SibSp IS NOT NULL\n",
    "    AND Parch IS NOT NULL\n",
    "    AND Ticket IS NOT NULL\n",
    "    AND Fare IS NOT NULL\n",
    "    AND Cabin IS NOT NULL\n",
    "    AND Embarked IS NOT NULL\n",
    "    GROUP BY Sex;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|    2|\n",
      "|       C|   65|\n",
      "|       S|  116|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.groupBy(\"Embarked\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(Embarked)|\n",
      "+---------------+\n",
      "|              2|\n",
      "|             65|\n",
      "|            116|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(Embarked) FROM titanic\n",
    "    WHERE PassengerId IS NOT NULL\n",
    "    AND Survived IS NOT NULL\n",
    "    AND Pclass IS NOT NULL\n",
    "    AND Name IS NOT NULL\n",
    "    AND Sex IS NOT NULL\n",
    "    AND Age IS NOT NULL\n",
    "    AND SibSp IS NOT NULL\n",
    "    AND Parch IS NOT NULL\n",
    "    AND Ticket IS NOT NULL\n",
    "    AND Fare IS NOT NULL\n",
    "    AND Cabin IS NOT NULL\n",
    "    AND Embarked IS NOT NULL\n",
    "    GROUP BY Embarked;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descriptive stats\n",
    "1. Pclass\n",
    "2. Age\n",
    "3. SibSp\n",
    "4. Parch\n",
    "5. Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+------------------+-------------------+----------------+\n",
      "|      avg(Pclass)|         avg(Age)|        avg(SibSp)|         avg(Parch)|       avg(Fare)|\n",
      "+-----------------+-----------------+------------------+-------------------+----------------+\n",
      "|2.308641975308642|29.69911764705882|0.5230078563411896|0.38159371492704824|32.2042079685746|\n",
      "+-----------------+-----------------+------------------+-------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").groupBy().avg(\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+------------------+-------------------+----------------+\n",
      "|      avg(Pclass)|         avg(Age)|        avg(SibSp)|         avg(Parch)|       avg(Fare)|\n",
      "+-----------------+-----------------+------------------+-------------------+----------------+\n",
      "|2.308641975308642|29.69911764705882|0.5230078563411896|0.38159371492704824|32.2042079685746|\n",
      "+-----------------+-----------------+------------------+-------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\" \n",
    "    SELECT AVG(Pclass), AVG(Age), AVG(SibSp), AVG(Parch), AVG(Fare) FROM titanic;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-------------------+-----------------+\n",
      "|summary|            Pclass|               Age|             SibSp|              Parch|             Fare|\n",
      "+-------+------------------+------------------+------------------+-------------------+-----------------+\n",
      "|  count|               891|               714|               891|                891|              891|\n",
      "|   mean| 2.308641975308642| 29.69911764705882|0.5230078563411896|0.38159371492704824| 32.2042079685746|\n",
      "| stddev|0.8360712409770491|14.526497332334035|1.1027434322934315| 0.8060572211299488|49.69342859718089|\n",
      "|    min|                 1|              0.42|                 0|                  0|              0.0|\n",
      "|    max|                 3|              80.0|                 8|                  6|         512.3292|\n",
      "+-------+------------------+------------------+------------------+-------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 16:05:18 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "df.describe(\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------------------+------------------+----+--------+-------+\n",
      "|Pclass|count|               mean|            stddev| min|     max| median|\n",
      "+------+-----+-------------------+------------------+----+--------+-------+\n",
      "|Pclass|  891|  2.308641975308642|0.8360712409770491| 1.0|     3.0|    3.0|\n",
      "|   Age|  714|  29.69911764705882|14.526497332334035|0.42|    80.0|   28.0|\n",
      "| SibSp|  891| 0.5230078563411896|1.1027434322934315| 0.0|     8.0|    0.0|\n",
      "| Parch|  891|0.38159371492704824|0.8060572211299488| 0.0|     6.0|    0.0|\n",
      "|  Fare|  891|   32.2042079685746| 49.69342859718089| 0.0|512.3292|14.4542|\n",
      "+------+-----+-------------------+------------------+----+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        'Pclass' AS Pclass,\n",
    "        COUNT(Pclass) AS count,\n",
    "        AVG(Pclass) AS mean,\n",
    "        STDDEV(Pclass) AS stddev,\n",
    "        MIN(Pclass) AS min,\n",
    "        MAX(Pclass) AS max,\n",
    "        PERCENTILE_APPROX(Pclass, 0.5) AS median\n",
    "    FROM titanic\n",
    "    UNION\n",
    "    SELECT\n",
    "        'Age' AS Age,\n",
    "        COUNT(Age) AS count,\n",
    "        AVG(Age) AS mean,\n",
    "        STDDEV(Age) AS stddev,\n",
    "        MIN(Age) AS min,\n",
    "        MAX(Age) AS max,\n",
    "        PERCENTILE_APPROX(Age, 0.5) AS median\n",
    "    FROM titanic\n",
    "    UNION\n",
    "    SELECT\n",
    "        'SibSp' AS SibSp,\n",
    "        COUNT(SibSp) AS count,\n",
    "        AVG(SibSp) AS mean,\n",
    "        STDDEV(SibSp) AS stddev,\n",
    "        MIN(SibSp) AS min,\n",
    "        MAX(SibSp) AS max,\n",
    "        PERCENTILE_APPROX(SibSp, 0.5) AS median\n",
    "    FROM titanic\n",
    "    UNION\n",
    "    SELECT\n",
    "        'Parch' AS Parch,\n",
    "        COUNT(Parch) AS count,\n",
    "        AVG(Parch) AS mean,\n",
    "        STDDEV(Parch) AS stddev,\n",
    "        MIN(Parch) AS min,\n",
    "        MAX(Parch) AS max,\n",
    "        PERCENTILE_APPROX(Parch, 0.5) AS median\n",
    "    FROM titanic\n",
    "    UNION\n",
    "    SELECT\n",
    "        'Fare' AS Fare,\n",
    "        COUNT(Fare) AS count,\n",
    "        AVG(Fare) AS mean,\n",
    "        STDDEV(Fare) AS stddev,\n",
    "        MIN(Fare) AS min,\n",
    "        MAX(Fare) AS max,\n",
    "        PERCENTILE_APPROX(Fare, 0.5) AS median\n",
    "    FROM titanic;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Pclass|         avg(Fare)|\n",
      "+------+------------------+\n",
      "|     1| 84.15468749999992|\n",
      "|     2| 20.66218315217391|\n",
      "|     3|13.675550101832997|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Pclass\", \"Fare\").groupBy(\"Pclass\").avg(\"Fare\").orderBy(\"Pclass\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Pclass|         avg(Fare)|\n",
      "+------+------------------+\n",
      "|     1| 84.15468749999992|\n",
      "|     2| 20.66218315217391|\n",
      "|     3|13.675550101832997|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT Pclass, AVG(Fare) FROM titanic\n",
    "    GROUP BY Pclass ORDER BY Pclass;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|Age Range|      Fare Average|\n",
      "+---------+------------------+\n",
      "|     0-10|30.434439062500008|\n",
      "|    10-20|  29.4696247863248|\n",
      "|    20-30|  27.1016648979592|\n",
      "|    30-40|40.141317777777786|\n",
      "|    40-50| 40.63093636363638|\n",
      "|    50-60| 48.47692307692308|\n",
      "|    60-70|47.642061904761896|\n",
      "|    70-80|30.169057142857145|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "price_age_df = df.filter(df.Fare.isNotNull())\n",
    "p1 = price_age_df.filter((df.Age >= 0) & (df.Age <= 10)).agg(f.avg(\"Fare\").alias(\"0-10\"))\n",
    "p2 = price_age_df.filter((df.Age >= 10) & (df.Age <= 20)).agg(f.avg(\"Fare\").alias(\"10-20\"))\n",
    "p3 = price_age_df.filter((df.Age >= 20) & (df.Age <= 30)).agg(f.avg(\"Fare\").alias(\"20-30\"))\n",
    "p4 = price_age_df.filter((df.Age >= 30) & (df.Age <= 40)).agg(f.avg(\"Fare\").alias(\"30-40\"))\n",
    "p5 = price_age_df.filter((df.Age >= 40) & (df.Age <= 50)).agg(f.avg(\"Fare\").alias(\"40-50\"))\n",
    "p6 = price_age_df.filter((df.Age >= 50) & (df.Age <= 60)).agg(f.avg(\"Fare\").alias(\"50-60\"))\n",
    "p7 = price_age_df.filter((df.Age >= 60) & (df.Age <= 70)).agg(f.avg(\"Fare\").alias(\"60-70\"))\n",
    "p8 = price_age_df.filter((df.Age >= 70) & (df.Age <= 80)).agg(f.avg(\"Fare\").alias(\"70-80\"))\n",
    "columns = [\"Age Range\",\"Fare Average\"]\n",
    "datas = [\n",
    "    (\"0-10\", p1.collect()[0][0]),\n",
    "    (\"10-20\", p2.collect()[0][0]),\n",
    "    (\"20-30\", p3.collect()[0][0]),\n",
    "    (\"30-40\", p4.collect()[0][0]),\n",
    "    (\"40-50\", p5.collect()[0][0]),\n",
    "    (\"50-60\", p6.collect()[0][0]),\n",
    "    (\"60-70\", p7.collect()[0][0]),\n",
    "    (\"70-80\", p8.collect()[0][0])\n",
    "]\n",
    "new_df = spark.createDataFrame(datas, columns)\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|AgeRange|           AvgFare|\n",
      "+--------+------------------+\n",
      "|    0-10| 30.57667903225807|\n",
      "|   10-20| 32.53513235294118|\n",
      "|   20-30|27.278937272727294|\n",
      "|   30-40|40.377294011976055|\n",
      "|   40-50| 38.00229662921349|\n",
      "|   50-60| 47.93333333333334|\n",
      "|   60-70| 48.36754210526315|\n",
      "|   70-80|30.197233333333333|\n",
      "|     80+|              30.0|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        CASE\n",
    "            WHEN Age > 0 AND Age < 10 THEN '0-10'\n",
    "            WHEN Age >= 10 AND Age < 20 THEN '10-20'\n",
    "            WHEN Age >= 20 AND Age < 30 THEN '20-30'\n",
    "            WHEN Age >= 30 AND Age < 40 THEN '30-40'\n",
    "            WHEN Age >= 40 AND Age < 50 THEN '40-50'\n",
    "            WHEN Age >= 50 AND Age < 60 THEN '50-60'\n",
    "            WHEN Age >= 60 AND Age < 70 THEN '60-70'\n",
    "            WHEN Age >= 70 AND Age < 80 THEN '70-80'\n",
    "            ELSE '80+'\n",
    "        END AS AgeRange,\n",
    "        AVG(Fare) AS AvgFare\n",
    "    FROM titanic\n",
    "    WHERE Age IS NOT NULL\n",
    "    GROUP BY AgeRange\n",
    "    ORDER BY AgeRange\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of Pclass Column: 3.0\n",
      "Median of Age Column: 28.0\n",
      "Median of SibSp Column: 0.0\n",
      "Median of Parch Column: 0.0\n",
      "Median of Fare Column: 14.4542\n"
     ]
    }
   ],
   "source": [
    "descriptive_columns = [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "for column in descriptive_columns:\n",
    "    quantiles = df.filter(df[column].isNotNull()).approxQuantile(column, [0.5], 0.01)\n",
    "    print(f\"Median of {column} Column: {float(quantiles[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+-------+\n",
      "|median|median|median|median| median|\n",
      "+------+------+------+------+-------+\n",
      "|     3|  28.0|     0|     0|14.4542|\n",
      "+------+------+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "    PERCENTILE_APPROX(Pclass, 0.5) AS median,\n",
    "    PERCENTILE_APPROX(Age, 0.5) AS median,\n",
    "    PERCENTILE_APPROX(SibSp, 0.5) AS median,\n",
    "    PERCENTILE_APPROX(Parch, 0.5) AS median,\n",
    "    PERCENTILE_APPROX(Fare, 0.5) AS median\n",
    "    FROM titanic\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+-----+--------+\n",
      "|Pclass| Age|SibSp|Parch|    Fare|\n",
      "+------+----+-----+-----+--------+\n",
      "|     1|0.92|    1|    2|  151.55|\n",
      "|     1| 2.0|    1|    2|  151.55|\n",
      "|     1| 4.0|    0|    2| 81.8583|\n",
      "|     1|11.0|    1|    2|   120.0|\n",
      "|     1|14.0|    1|    2|   120.0|\n",
      "|     1|15.0|    0|    1|211.3375|\n",
      "|     1|16.0|    0|    0|    86.5|\n",
      "|     1|16.0|    0|    1|    39.4|\n",
      "|     1|16.0|    0|    1| 57.9792|\n",
      "|     1|17.0|    0|    2|110.8833|\n",
      "|     1|17.0|    1|    0|    57.0|\n",
      "|     1|17.0|    1|    0|   108.9|\n",
      "|     1|18.0|    0|    2|   79.65|\n",
      "|     1|18.0|    1|    0|   108.9|\n",
      "|     1|18.0|    1|    0| 227.525|\n",
      "|     1|18.0|    2|    2| 262.375|\n",
      "|     1|19.0|    0|    0|    30.0|\n",
      "|     1|19.0|    0|    2| 26.2833|\n",
      "|     1|19.0|    1|    0|    53.1|\n",
      "|     1|19.0|    1|    0| 91.0792|\n",
      "+------+----+-----+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT Pclass, Age, SibSp, Parch, Fare FROM titanic \n",
    "    WHERE\n",
    "    Pclass IS NOT NULL AND\n",
    "    Age IS NOT NULL AND\n",
    "    SibSp IS NOT NULL AND\n",
    "    Parch IS NOT NULL AND\n",
    "    Fare IS NOT NULL\n",
    "    ORDER BY Pclass, Age, SibSp, Parch, Fare;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|family_size|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|          1|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|          1|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|          0|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|          1|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|          0|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|          0|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|          0|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|          4|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|          2|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|          1|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"family_size\", df[\"SibSp\"] + df[\"Parch\"]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|family_size|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|          1|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|          1|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|          0|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|          1|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|          0|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|          0|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|          0|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|          4|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|          2|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|          1|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|          2|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|          0|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|          0|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| NULL|       S|          6|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| NULL|       S|          0|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| NULL|       S|          0|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| NULL|       Q|          5|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|    0|          244373|   13.0| NULL|       S|          0|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| NULL|       S|          1|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|    0|            2649|  7.225| NULL|       C|          0|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT *, (SibSp + Parch) AS family_size FROM titanic;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+---------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|age_group|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+---------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|    Adult|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Adult|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|    Adult|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|    Adult|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|    Adult|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|   Senior|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|    Adult|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|    Minor|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|    Adult|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|    Minor|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|    Minor|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|    Adult|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|    Adult|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| NULL|       S|    Adult|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| NULL|       S|    Minor|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| NULL|       S|    Adult|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| NULL|       Q|    Minor|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|    0|          244373|   13.0| NULL|       S|   Senior|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| NULL|       S|    Adult|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|    0|            2649|  7.225| NULL|       C|   Senior|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"age_group\", f.when(df.Age < 18, \"Minor\").when(df.Age<65,\"Adult\").otherwise(\"Senior\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+---------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|age_group|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+---------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|    Adult|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Adult|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|    Adult|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|    Adult|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|    Adult|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|   Senior|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|    Adult|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|    Minor|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|    Adult|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|    Minor|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|    Minor|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|    Adult|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|    Adult|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| NULL|       S|    Adult|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| NULL|       S|    Minor|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| NULL|       S|    Adult|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| NULL|       Q|    Minor|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|    0|          244373|   13.0| NULL|       S|   Senior|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| NULL|       S|    Adult|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|    0|            2649|  7.225| NULL|       C|   Senior|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT *, CASE \n",
    "        WHEN Age < 18 THEN \"Minor\"\n",
    "        WHEN Age < 65 THEN \"Adult\"\n",
    "        ELSE \"Senior\"\n",
    "        END AS age_group\n",
    "    FROM titanic;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
