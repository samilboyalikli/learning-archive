{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"house_price_prediction_dataset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"houses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SCOPE\n",
    "Here I try to get the requests with spark methods and sql queries. The requests according to `house_price_simple_analysis.py` file:\n",
    "01. Schema of the dataset.\n",
    "02. Row count of the dataset.\n",
    "03. Column count of the dataset.\n",
    "04. Describes of descriptive stats.\n",
    "05. Min of descriptive stats.\n",
    "06. Max of descriptive stats.\n",
    "07. Null control for some columns.\n",
    "08. Fill null rows.\n",
    "09. Bedrooms biggest than three.\n",
    "10. Year built < 2010.\n",
    "11. Location count.\n",
    "12. Price order by location.\n",
    "13. Price per square.\n",
    "14. Order by price.\n",
    "15. Price by area.\n",
    "16. Adding has_garage column to dataset.<br><br><br>\n",
    "***  \n",
    "##### TODO\n",
    "\n",
    "- [x] Schema of the dataset.\n",
    "- [x] Row count of the dataset.\n",
    "- [x] Column count of the dataset.\n",
    "- [x] Describes of descriptive stats.\n",
    "- [x] Min of descriptive stats.\n",
    "- [x] Max of descriptive stats.\n",
    "- [ ] Null control for some columns.\n",
    "- [ ] Fill null rows.\n",
    "- [ ] Bedrooms biggest than three.\n",
    "- [ ] Year built < 2010.\n",
    "- [ ] Location count.\n",
    "- [ ] Price order by location.\n",
    "- [ ] Price per square.\n",
    "- [ ] Order by price.\n",
    "- [ ] Price by area.\n",
    "- [ ] Adding has_garage column to dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Area: integer (nullable = true)\n",
      " |-- Bedrooms: integer (nullable = true)\n",
      " |-- Bathrooms: integer (nullable = true)\n",
      " |-- Floors: integer (nullable = true)\n",
      " |-- YearBuilt: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Condition: string (nullable = true)\n",
      " |-- Garage: string (nullable = true)\n",
      " |-- Price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_of_dataset_py = df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------+\n",
      "| col_name|data_type|comment|\n",
      "+---------+---------+-------+\n",
      "|       Id|      int|   NULL|\n",
      "|     Area|      int|   NULL|\n",
      "| Bedrooms|      int|   NULL|\n",
      "|Bathrooms|      int|   NULL|\n",
      "|   Floors|      int|   NULL|\n",
      "|YearBuilt|      int|   NULL|\n",
      "| Location|   string|   NULL|\n",
      "|Condition|   string|   NULL|\n",
      "|   Garage|   string|   NULL|\n",
      "|    Price|      int|   NULL|\n",
      "+---------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_of_dataset_sql = spark.sql(\"DESCRIBE houses;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count of the Dataset:  2000\n"
     ]
    }
   ],
   "source": [
    "count_of_dataset_py = df.count()\n",
    "print(\"Row Count of the Dataset: \",count_of_dataset_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|row_count|\n",
      "+---------+\n",
      "|     2000|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_of_dataset_sql = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(*) AS row_count FROM houses;\n",
    "    \"\"\"\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Count of the Dataset:  10\n"
     ]
    }
   ],
   "source": [
    "column_count_of_dataset_py = len(df.columns)\n",
    "print(\"Column Count of the Dataset: \", column_count_of_dataset_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|column_count|\n",
      "+------------+\n",
      "|          10|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_count_of_dataset_sql = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT SIZE(ARRAY(*)) AS column_count FROM houses LIMIT 1;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/17 20:30:57 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+-----------------+-----------------+\n",
      "|summary|         Bedrooms|         Bathrooms|            Floors|        YearBuilt|            Price|\n",
      "+-------+-----------------+------------------+------------------+-----------------+-----------------+\n",
      "|  count|             2000|              2000|              2000|             2000|             2000|\n",
      "|   mean|           3.0035|            2.5525|            1.9935|         1961.446|       537676.855|\n",
      "| stddev|1.424606086344792|1.1089899365366986|0.8091879525618783|35.92669547458914|276428.8457191392|\n",
      "|    min|                1|                 1|                 1|             1900|            50005|\n",
      "|    max|                5|                 4|                 3|             2023|           999656|\n",
      "+-------+-----------------+------------------+------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(\"Bedrooms\", \"Bathrooms\", \"Floors\", \"YearBuilt\", \"Price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+----------+------------------+-----+------+\n",
      "|  summary|count|      mean|            stddev|  min|   max|\n",
      "+---------+-----+----------+------------------+-----+------+\n",
      "| Bedrooms| 2000|    3.0035| 1.424606086344792|    1|     5|\n",
      "|Bathrooms| 2000|    2.5525|1.1089899365366986|    1|     4|\n",
      "|   Floors| 2000|    1.9935|0.8091879525618783|    1|     3|\n",
      "|YearBuilt| 2000|  1961.446| 35.92669547458914| 1900|  2023|\n",
      "|    Price| 2000|537676.855| 276428.8457191392|50005|999656|\n",
      "+---------+-----+----------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        'Bedrooms' AS summary,\n",
    "        COUNT(Bedrooms) AS count,\n",
    "        AVG(Bedrooms) AS mean,\n",
    "        STDDEV(Bedrooms) AS stddev,\n",
    "        MIN(Bedrooms) AS min,\n",
    "        MAX(Bedrooms) AS max\n",
    "    FROM houses\n",
    "    UNION\n",
    "    SELECT\n",
    "        'Bathrooms' AS summary,\n",
    "        COUNT(Bathrooms) AS count,\n",
    "        AVG(Bathrooms) AS mean,\n",
    "        STDDEV(Bathrooms) AS stddev,\n",
    "        MIN(Bathrooms) AS min,\n",
    "        MAX(Bathrooms) AS max\n",
    "    FROM houses\n",
    "    UNION\n",
    "    SELECT\n",
    "        'Floors' AS summary,\n",
    "        COUNT(Floors) AS count,\n",
    "        AVG(Floors) AS mean,\n",
    "        STDDEV(Floors) AS stddev,\n",
    "        MIN(Floors) AS min,\n",
    "        MAX(Floors) AS max\n",
    "    FROM houses\n",
    "    UNION\n",
    "    SELECT\n",
    "        'YearBuilt' AS summary,\n",
    "        COUNT(YearBuilt) AS count,\n",
    "        AVG(YearBuilt) AS mean,\n",
    "        STDDEV(YearBuilt) AS stddev,\n",
    "        MIN(YearBuilt) AS min,\n",
    "        MAX(YearBuilt) AS max\n",
    "    FROM houses\n",
    "    UNION\n",
    "    SELECT\n",
    "        'Price' AS summary,\n",
    "        COUNT(Price) AS count,\n",
    "        AVG(Price) AS mean,\n",
    "        STDDEV(Price) AS stddev,\n",
    "        MIN(Price) AS min,\n",
    "        MAX(Price) AS max\n",
    "    FROM houses;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|min(Bedrooms)|min(Bathrooms)|min(Floors)|min(YearBuilt)|min(Price)|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|            1|             1|          1|          1900|     50005|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Bedrooms\", \"Bathrooms\", \"Floors\", \"YearBuilt\", \"Price\").groupBy() \\\n",
    "  .min(\"Bedrooms\", \"Bathrooms\", \"Floors\", \"YearBuilt\", \"Price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|min(Bedrooms)|min(Bathrooms)|min(Floors)|min(YearBuilt)|min(Price)|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|            1|             1|          1|          1900|     50005|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT MIN(Bedrooms), MIN(Bathrooms), MIN(Floors), MIN(YearBuilt), MIN(Price) FROM houses;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|max(Bedrooms)|max(Bathrooms)|max(Floors)|max(YearBuilt)|max(Price)|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|            5|             4|          3|          2023|    999656|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Bedrooms\", \"Bathrooms\", \"Floors\", \"YearBuilt\", \"Price\").groupBy() \\\n",
    "  .max(\"Bedrooms\", \"Bathrooms\", \"Floors\", \"YearBuilt\", \"Price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|max(Bedrooms)|max(Bathrooms)|max(Floors)|max(YearBuilt)|max(Price)|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|            5|             4|          3|          2023|    999656|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT MAX(Bedrooms), MAX(Bathrooms), MAX(Floors), MAX(YearBuilt), MAX(Price) FROM houses;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+---------+------+---------+--------+---------+------+-----+\n",
      "| Id|Area|Bedrooms|Bathrooms|Floors|YearBuilt|Location|Condition|Garage|Price|\n",
      "+---+----+--------+---------+------+---------+--------+---------+------+-----+\n",
      "+---+----+--------+---------+------+---------+--------+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"Id\"].isNull()).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
