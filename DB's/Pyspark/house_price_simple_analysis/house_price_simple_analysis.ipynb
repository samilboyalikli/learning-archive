{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"house_price_prediction_dataset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"houses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SCOPE\n",
    "Here I try to get the requests with spark methods and sql queries. The requests according to `house_price_simple_analysis.py` file:\n",
    "01. Schema of the dataset.\n",
    "02. Row count of the dataset.\n",
    "03. Column count of the dataset.\n",
    "04. Describes of descriptive stats.\n",
    "05. Min of descriptive stats.\n",
    "06. Max of descriptive stats.\n",
    "07. Null control for some columns.\n",
    "08. Fill null rows.\n",
    "09. Bedrooms biggest than three.\n",
    "10. Year built < 2010.\n",
    "11. Location count.\n",
    "12. Price group by location.\n",
    "13. Price per square.\n",
    "14. Order by price.\n",
    "15. Price by area.\n",
    "16. Adding has_garage column to dataset.<br><br><br>\n",
    "***  \n",
    "##### TODO\n",
    "\n",
    "- [x] Schema of the dataset.\n",
    "- [x] Row count of the dataset.\n",
    "- [x] Column count of the dataset.\n",
    "- [x] Describes of descriptive stats.\n",
    "- [x] Min of descriptive stats.\n",
    "- [x] Max of descriptive stats.\n",
    "- [x] Null control for some columns.\n",
    "- [x] Fill null rows.\n",
    "- [x] Bedrooms biggest than three.\n",
    "- [x] Year built < 2010.\n",
    "- [x] Location count.\n",
    "- [x] Price group by location.\n",
    "- [x] Price per square.\n",
    "- [x] Order by price.\n",
    "- [x] Price by area.\n",
    "- [x] Adding has_garage column to dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Area: integer (nullable = true)\n",
      " |-- Bedrooms: integer (nullable = true)\n",
      " |-- Bathrooms: integer (nullable = true)\n",
      " |-- Floors: integer (nullable = true)\n",
      " |-- YearBuilt: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Condition: string (nullable = true)\n",
      " |-- Garage: string (nullable = true)\n",
      " |-- Price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_of_dataset_py = df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------+\n",
      "| col_name|data_type|comment|\n",
      "+---------+---------+-------+\n",
      "|       Id|      int|   NULL|\n",
      "|     Area|      int|   NULL|\n",
      "| Bedrooms|      int|   NULL|\n",
      "|Bathrooms|      int|   NULL|\n",
      "|   Floors|      int|   NULL|\n",
      "|YearBuilt|      int|   NULL|\n",
      "| Location|   string|   NULL|\n",
      "|Condition|   string|   NULL|\n",
      "|   Garage|   string|   NULL|\n",
      "|    Price|      int|   NULL|\n",
      "+---------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_of_dataset_sql = spark.sql(\"DESCRIBE houses;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count of the Dataset:  2000\n"
     ]
    }
   ],
   "source": [
    "count_of_dataset_py = df.count()\n",
    "print(\"Row Count of the Dataset: \",count_of_dataset_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|row_count|\n",
      "+---------+\n",
      "|     2000|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_of_dataset_sql = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(*) AS row_count FROM houses;\n",
    "    \"\"\"\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Count of the Dataset:  10\n"
     ]
    }
   ],
   "source": [
    "column_count_of_dataset_py = len(df.columns)\n",
    "print(\"Column Count of the Dataset: \", column_count_of_dataset_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|column_count|\n",
      "+------------+\n",
      "|          10|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_count_of_dataset_sql = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT SIZE(ARRAY(*)) AS column_count FROM houses LIMIT 1;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/17 20:30:57 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+-----------------+-----------------+\n",
      "|summary|         Bedrooms|         Bathrooms|            Floors|        YearBuilt|            Price|\n",
      "+-------+-----------------+------------------+------------------+-----------------+-----------------+\n",
      "|  count|             2000|              2000|              2000|             2000|             2000|\n",
      "|   mean|           3.0035|            2.5525|            1.9935|         1961.446|       537676.855|\n",
      "| stddev|1.424606086344792|1.1089899365366986|0.8091879525618783|35.92669547458914|276428.8457191392|\n",
      "|    min|                1|                 1|                 1|             1900|            50005|\n",
      "|    max|                5|                 4|                 3|             2023|           999656|\n",
      "+-------+-----------------+------------------+------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(\"Bedrooms\", \"Bathrooms\", \"Floors\", \"YearBuilt\", \"Price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+----------+------------------+-----+------+\n",
      "|  summary|count|      mean|            stddev|  min|   max|\n",
      "+---------+-----+----------+------------------+-----+------+\n",
      "| Bedrooms| 2000|    3.0035| 1.424606086344792|    1|     5|\n",
      "|Bathrooms| 2000|    2.5525|1.1089899365366986|    1|     4|\n",
      "|   Floors| 2000|    1.9935|0.8091879525618783|    1|     3|\n",
      "|YearBuilt| 2000|  1961.446| 35.92669547458914| 1900|  2023|\n",
      "|    Price| 2000|537676.855| 276428.8457191392|50005|999656|\n",
      "+---------+-----+----------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        'Bedrooms' AS summary,\n",
    "        COUNT(Bedrooms) AS count,\n",
    "        AVG(Bedrooms) AS mean,\n",
    "        STDDEV(Bedrooms) AS stddev,\n",
    "        MIN(Bedrooms) AS min,\n",
    "        MAX(Bedrooms) AS max\n",
    "    FROM houses\n",
    "    UNION\n",
    "    SELECT\n",
    "        'Bathrooms' AS summary,\n",
    "        COUNT(Bathrooms) AS count,\n",
    "        AVG(Bathrooms) AS mean,\n",
    "        STDDEV(Bathrooms) AS stddev,\n",
    "        MIN(Bathrooms) AS min,\n",
    "        MAX(Bathrooms) AS max\n",
    "    FROM houses\n",
    "    UNION\n",
    "    SELECT\n",
    "        'Floors' AS summary,\n",
    "        COUNT(Floors) AS count,\n",
    "        AVG(Floors) AS mean,\n",
    "        STDDEV(Floors) AS stddev,\n",
    "        MIN(Floors) AS min,\n",
    "        MAX(Floors) AS max\n",
    "    FROM houses\n",
    "    UNION\n",
    "    SELECT\n",
    "        'YearBuilt' AS summary,\n",
    "        COUNT(YearBuilt) AS count,\n",
    "        AVG(YearBuilt) AS mean,\n",
    "        STDDEV(YearBuilt) AS stddev,\n",
    "        MIN(YearBuilt) AS min,\n",
    "        MAX(YearBuilt) AS max\n",
    "    FROM houses\n",
    "    UNION\n",
    "    SELECT\n",
    "        'Price' AS summary,\n",
    "        COUNT(Price) AS count,\n",
    "        AVG(Price) AS mean,\n",
    "        STDDEV(Price) AS stddev,\n",
    "        MIN(Price) AS min,\n",
    "        MAX(Price) AS max\n",
    "    FROM houses;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|min(Bedrooms)|min(Bathrooms)|min(Floors)|min(YearBuilt)|min(Price)|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|            1|             1|          1|          1900|     50005|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Bedrooms\", \"Bathrooms\", \"Floors\", \"YearBuilt\", \"Price\").groupBy() \\\n",
    "  .min(\"Bedrooms\", \"Bathrooms\", \"Floors\", \"YearBuilt\", \"Price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|min(Bedrooms)|min(Bathrooms)|min(Floors)|min(YearBuilt)|min(Price)|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|            1|             1|          1|          1900|     50005|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT MIN(Bedrooms), MIN(Bathrooms), MIN(Floors), MIN(YearBuilt), MIN(Price) FROM houses;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|max(Bedrooms)|max(Bathrooms)|max(Floors)|max(YearBuilt)|max(Price)|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|            5|             4|          3|          2023|    999656|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Bedrooms\", \"Bathrooms\", \"Floors\", \"YearBuilt\", \"Price\").groupBy() \\\n",
    "  .max(\"Bedrooms\", \"Bathrooms\", \"Floors\", \"YearBuilt\", \"Price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|max(Bedrooms)|max(Bathrooms)|max(Floors)|max(YearBuilt)|max(Price)|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "|            5|             4|          3|          2023|    999656|\n",
      "+-------------+--------------+-----------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT MAX(Bedrooms), MAX(Bathrooms), MAX(Floors), MAX(YearBuilt), MAX(Price) FROM houses;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id: 0\n",
      "Area: 0\n",
      "Bedrooms: 0\n",
      "Bathrooms: 0\n",
      "Floors: 0\n",
      "YearBuilt: 0\n",
      "Location: 0\n",
      "Condition: 0\n",
      "Garage: 0\n",
      "Price: 0\n"
     ]
    }
   ],
   "source": [
    "columns = [\"Id\", \"Area\", \"Bedrooms\", \"Bathrooms\", \"Floors\", \"YearBuilt\", \"Location\", \"Condition\", \"Garage\", \"Price\"]\n",
    "for col in columns:\n",
    "    result = df.filter(df[col].isNull()).count()\n",
    "    print(f\"{col}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        COUNT(Id) IS NOT NULL,\n",
    "        Area IS NOT NULL,\n",
    "        Bedrooms IS NOT NULL, \n",
    "        Bathrooms IS NOT NULL, \n",
    "        Floors IS NOT NULL, \n",
    "        YearBuilt IS NOT NULL, \n",
    "        Location IS NOT NULL, \n",
    "        Condition IS NOT NULL, \n",
    "        Garage IS NOT NULL, \n",
    "        Price IS NOT NULL\n",
    "    FROM houses;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = df.select(\"Id\").groupBy().max(\"Id\").collect()[0][0]\n",
    "area = df.select(\"Area\").groupBy().avg(\"Area\").collect()[0][0]\n",
    "bedrooms = df.select(\"Bedrooms\").groupBy().avg(\"Bedrooms\").collect()[0][0]\n",
    "bathrooms = df.select(\"Bathrooms\").groupBy().avg(\"Bathrooms\").collect()[0][0]\n",
    "floors = df.select(\"Floors\").groupBy().avg(\"Floors\").collect()[0][0]\n",
    "yearbuilt = df.select(\"YearBuilt\").groupBy().avg(\"YearBuilt\").collect()[0][0]\n",
    "price = df.select(\"Price\").groupBy().avg(\"Price\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+---------+------+---------+--------+---------+------+------+\n",
      "| Id|Area|Bedrooms|Bathrooms|Floors|YearBuilt|Location|Condition|Garage| Price|\n",
      "+---+----+--------+---------+------+---------+--------+---------+------+------+\n",
      "|  1|1360|       5|        4|     3|     1970|Downtown|Excellent|    No|149919|\n",
      "|  2|4272|       5|        4|     3|     1958|Downtown|Excellent|    No|424998|\n",
      "|  3|3592|       2|        2|     3|     1938|Downtown|     Good|    No|266746|\n",
      "|  4| 966|       4|        2|     2|     1902|Suburban|     Fair|   Yes|244020|\n",
      "|  5|4926|       1|        4|     2|     1975|Downtown|     Fair|   Yes|636056|\n",
      "|  6|3944|       1|        2|     1|     1906|   Urban|     Poor|    No| 93262|\n",
      "|  7|3671|       1|        1|     2|     1948|   Rural|     Poor|   Yes|448722|\n",
      "|  8|3419|       2|        4|     1|     1925|Suburban|     Good|   Yes|594893|\n",
      "|  9| 630|       2|        2|     1|     1932|   Rural|     Poor|   Yes|652878|\n",
      "| 10|2185|       3|        3|     1|     2000|Downtown|     Poor|    No|340375|\n",
      "+---+----+--------+---------+------+---------+--------+---------+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill({\n",
    "    'Id': id+1,\n",
    "    'Area': area,\n",
    "    'Bedrooms': bedrooms,\n",
    "    \"Bathrooms\": bathrooms,\n",
    "    \"Floors\": floors,\n",
    "    \"YearBuilt\": yearbuilt,\n",
    "    'Location': 'unknown',\n",
    "    'Condition': 'unknown',\n",
    "    'Garage': 'unknown',\n",
    "    \"Price\": price\n",
    "}).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A point:\n",
    "There is no chance here to coding a sql query can insert data to null rows. I tried a code block but I taked Unsupported Operation Error directly. Because of that, we can use Delta Lake here. But it will take a lot of time, so maybe I will try later with Delta Lake.  \n",
    "\n",
    "For now I just show the empty lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+---------+------+---------+-----+\n",
      "| Id|Area|Bedrooms|Bathrooms|Floors|YearBuilt|Price|\n",
      "+---+----+--------+---------+------+---------+-----+\n",
      "+---+----+--------+---------+------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT Id, Area, Bedrooms, Bathrooms, Floors, YearBuilt, Price FROM houses WHERE Id IS NULL;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808\n"
     ]
    }
   ],
   "source": [
    "bedrooms_biggest_than_three = df.filter(df.Bedrooms > 3).count()\n",
    "print(bedrooms_biggest_than_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|bedrooms_biggest_than_three|\n",
      "+---------------------------+\n",
      "|                        808|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(Bedrooms) AS bedrooms_biggest_than_three FROM houses WHERE Bedrooms > 3;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1779\n"
     ]
    }
   ],
   "source": [
    "year_built_less_than_2010 = df.filter(df.YearBuilt < 2010).count()\n",
    "print(year_built_less_than_2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|year_built_less_than_2010|\n",
      "+-------------------------+\n",
      "|                     1779|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(YearBuilt) AS year_built_less_than_2010 FROM houses WHERE YearBuilt < 2010;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Location|count|\n",
      "+--------+-----+\n",
      "|   Urban|  485|\n",
      "|Suburban|  483|\n",
      "|Downtown|  558|\n",
      "|   Rural|  474|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Location\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Location|Count|\n",
      "+--------+-----+\n",
      "|   Urban|  485|\n",
      "|Suburban|  483|\n",
      "|Downtown|  558|\n",
      "|   Rural|  474|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT Location, COUNT(Location) AS Count FROM houses GROUP BY Location;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|Location|        avg(Price)|\n",
      "+--------+------------------+\n",
      "|   Urban|518963.54845360824|\n",
      "|Suburban| 557416.3333333334|\n",
      "|Downtown| 536059.6612903225|\n",
      "|   Rural| 538613.9430379746|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Location\").avg(\"Price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|Location|        avg(Price)|\n",
      "+--------+------------------+\n",
      "|   Urban|518963.54845360824|\n",
      "|Suburban| 557416.3333333334|\n",
      "|Downtown| 536059.6612903225|\n",
      "|   Rural| 538613.9430379746|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT Location, AVG(Price) FROM houses GROUP BY Location;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+---------+------+---------+--------+---------+------+------+------------------+\n",
      "| Id|Area|Bedrooms|Bathrooms|Floors|YearBuilt|Location|Condition|Garage| Price|  price_per_square|\n",
      "+---+----+--------+---------+------+---------+--------+---------+------+------+------------------+\n",
      "|  1|1360|       5|        4|     3|     1970|Downtown|Excellent|    No|149919|110.23455882352941|\n",
      "|  2|4272|       5|        4|     3|     1958|Downtown|Excellent|    No|424998| 99.48455056179775|\n",
      "|  3|3592|       2|        2|     3|     1938|Downtown|     Good|    No|266746| 74.26113585746103|\n",
      "|  4| 966|       4|        2|     2|     1902|Suburban|     Fair|   Yes|244020| 252.6086956521739|\n",
      "|  5|4926|       1|        4|     2|     1975|Downtown|     Fair|   Yes|636056|129.12220868859114|\n",
      "+---+----+--------+---------+------+---------+--------+---------+------+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"price_per_square\", (df.Price/df.Area)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+---------+------+---------+--------+---------+------+------+------------------+\n",
      "| Id|Area|Bedrooms|Bathrooms|Floors|YearBuilt|Location|Condition|Garage| Price|  price_per_square|\n",
      "+---+----+--------+---------+------+---------+--------+---------+------+------+------------------+\n",
      "|  1|1360|       5|        4|     3|     1970|Downtown|Excellent|    No|149919|110.23455882352941|\n",
      "|  2|4272|       5|        4|     3|     1958|Downtown|Excellent|    No|424998| 99.48455056179775|\n",
      "|  3|3592|       2|        2|     3|     1938|Downtown|     Good|    No|266746| 74.26113585746103|\n",
      "|  4| 966|       4|        2|     2|     1902|Suburban|     Fair|   Yes|244020| 252.6086956521739|\n",
      "|  5|4926|       1|        4|     2|     1975|Downtown|     Fair|   Yes|636056|129.12220868859114|\n",
      "+---+----+--------+---------+------+---------+--------+---------+------+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT *, (Price/Area) AS price_per_square FROM houses;\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+---------+------+---------+--------+---------+------+-----+\n",
      "|  Id|Area|Bedrooms|Bathrooms|Floors|YearBuilt|Location|Condition|Garage|Price|\n",
      "+----+----+--------+---------+------+---------+--------+---------+------+-----+\n",
      "|1168|4260|       2|        2|     1|     1907|   Rural|     Fair|   Yes|50005|\n",
      "| 837|2871|       4|        2|     1|     1914|Suburban|     Poor|    No|50064|\n",
      "|1729| 509|       4|        1|     2|     1993|   Urban|     Fair|    No|51082|\n",
      "|1593|4368|       5|        4|     2|     1976|Downtown|     Fair|    No|51845|\n",
      "|1464|4138|       3|        4|     1|     1960|   Urban|     Fair|    No|52024|\n",
      "+----+----+--------+---------+------+---------+--------+---------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df.Price.asc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+---------+------+---------+--------+---------+------+-----+\n",
      "|  Id|Area|Bedrooms|Bathrooms|Floors|YearBuilt|Location|Condition|Garage|Price|\n",
      "+----+----+--------+---------+------+---------+--------+---------+------+-----+\n",
      "|1168|4260|       2|        2|     1|     1907|   Rural|     Fair|   Yes|50005|\n",
      "| 837|2871|       4|        2|     1|     1914|Suburban|     Poor|    No|50064|\n",
      "|1729| 509|       4|        1|     2|     1993|   Urban|     Fair|    No|51082|\n",
      "|1593|4368|       5|        4|     2|     1976|Downtown|     Fair|    No|51845|\n",
      "|1464|4138|       3|        4|     1|     1960|   Urban|     Fair|    No|52024|\n",
      "+----+----+--------+---------+------+---------+--------+---------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM houses ORDER BY Price;\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+---------+------+---------+--------+---------+------+------+\n",
      "|  Id|Area|Bedrooms|Bathrooms|Floors|YearBuilt|Location|Condition|Garage| Price|\n",
      "+----+----+--------+---------+------+---------+--------+---------+------+------+\n",
      "| 206|4999|       4|        2|     1|     1967|Downtown|Excellent|    No|139460|\n",
      "|1123|4997|       2|        2|     2|     1918|   Urban|Excellent|    No|286887|\n",
      "| 161|4996|       1|        1|     1|     2005|Downtown|     Fair|    No|369733|\n",
      "| 233|4996|       2|        1|     3|     1943|   Urban|     Fair|   Yes|784184|\n",
      "| 300|4995|       2|        1|     3|     1925|   Urban|     Good|    No|286028|\n",
      "+----+----+--------+---------+------+---------+--------+---------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy([\"Area\", \"Price\"], ascending=[False, True]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+---------+------+---------+--------+---------+------+------+\n",
      "|  Id|Area|Bedrooms|Bathrooms|Floors|YearBuilt|Location|Condition|Garage| Price|\n",
      "+----+----+--------+---------+------+---------+--------+---------+------+------+\n",
      "| 206|4999|       4|        2|     1|     1967|Downtown|Excellent|    No|139460|\n",
      "|1123|4997|       2|        2|     2|     1918|   Urban|Excellent|    No|286887|\n",
      "| 161|4996|       1|        1|     1|     2005|Downtown|     Fair|    No|369733|\n",
      "| 233|4996|       2|        1|     3|     1943|   Urban|     Fair|   Yes|784184|\n",
      "| 300|4995|       2|        1|     3|     1925|   Urban|     Good|    No|286028|\n",
      "+----+----+--------+---------+------+---------+--------+---------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM houses ORDER BY Area DESC, Price;\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+---------+------+---------+--------+---------+------+------+----------+\n",
      "| Id|Area|Bedrooms|Bathrooms|Floors|YearBuilt|Location|Condition|Garage| Price|has_garage|\n",
      "+---+----+--------+---------+------+---------+--------+---------+------+------+----------+\n",
      "|  1|1360|       5|        4|     3|     1970|Downtown|Excellent|    No|149919|     false|\n",
      "|  2|4272|       5|        4|     3|     1958|Downtown|Excellent|    No|424998|     false|\n",
      "|  3|3592|       2|        2|     3|     1938|Downtown|     Good|    No|266746|     false|\n",
      "|  4| 966|       4|        2|     2|     1902|Suburban|     Fair|   Yes|244020|      true|\n",
      "|  5|4926|       1|        4|     2|     1975|Downtown|     Fair|   Yes|636056|      true|\n",
      "+---+----+--------+---------+------+---------+--------+---------+------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"has_garage\", f.when(df.Garage == \"Yes\", True).otherwise(False)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|has_garage|Garage|\n",
      "+----------+------+\n",
      "|     false|    No|\n",
      "|     false|    No|\n",
      "|     false|    No|\n",
      "|      true|   Yes|\n",
      "|      true|   Yes|\n",
      "+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT CASE \n",
    "        WHEN Garage = 'Yes' THEN True\n",
    "        ELSE False\n",
    "        END AS has_garage, Garage FROM houses;\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
