{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/12/20 20:43:22 WARN Utils: Your hostname, DESKTOP-H50ARNK resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/12/20 20:43:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/20 20:43:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"dataset_Vaccine_Pfizer.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"pfizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SCOPE\n",
    "\n",
    "1. Schema of the dataset.\n",
    "2. Number of tweets.\n",
    "3. Polarity of users.\n",
    "4. Count of contain pfizer.\n",
    "5. Tallest tweet.\n",
    "6. Most used word.\n",
    "7. Subjectivity of targets.\n",
    "8. Data cleaning.\n",
    "9. Relationship between Subjectivity and Polarity. <br><br><br>\n",
    "***  \n",
    "<br>\n",
    "\n",
    "- [x] Schema of the dataset.\n",
    "- [x] Number of tweets.\n",
    "- [x] Polarity of users.\n",
    "- [x] Count of contain pfizer.\n",
    "- [x] Tallest tweet.\n",
    "- [x] Most used word.\n",
    "- [ ] Subjectivity of targets.\n",
    "- [x] Data cleaning.\n",
    "- [ ] Relationship between Subjectivity and Polarity.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Subjectivity: string (nullable = true)\n",
      " |-- Polarity: string (nullable = true)\n",
      " |-- Target: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+\n",
      "|    col_name|data_type|comment|\n",
      "+------------+---------+-------+\n",
      "|          id|   string|   NULL|\n",
      "|        Text|   string|   NULL|\n",
      "|Subjectivity|   string|   NULL|\n",
      "|    Polarity|   string|   NULL|\n",
      "|      Target|   string|   NULL|\n",
      "+------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    DESCRIBE pfizer;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188\n"
     ]
    }
   ],
   "source": [
    "number_of_tweets = df.filter(df.Text.isNotNull()).count()\n",
    "print(number_of_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|number_of_tweets|\n",
      "+----------------+\n",
      "|            1188|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(Text) AS number_of_tweets FROM pfizer WHERE Text IS NOT NULL;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|           Polarity|\n",
      "+-------+-------------------+\n",
      "|  count|               1128|\n",
      "|   mean|0.16325622765526784|\n",
      "| stddev|0.25291704571613854|\n",
      "|    min|       -0.008333333|\n",
      "|    max|           Positive|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(\"Polarity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------------+--------+--------+-----------------+\n",
      "|       id|                Text|Subjectivity|Polarity|  Target|polarity_of_users|\n",
      "+---------+--------------------+------------+--------+--------+-----------------+\n",
      "|        0|Historically ther...|        0.45|    0.35|Positive|         Positive|\n",
      "|        1|Honored and Pfize...| 0.066666667|       0| Neutral|          Neutral|\n",
      "|        2|COVID19 illuminat...|        NULL|    NULL|    NULL|             NULL|\n",
      "|Next week| our Chief Develo...|           0|       0| Neutral|          Neutral|\n",
      "|        3|Today we publishe...|           0|       0| Neutral|          Neutral|\n",
      "+---------+--------------------+------------+--------+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tolerance = 0.0001\n",
    "df.withColumn(\"polarity_of_users\", f.when(df.Polarity<-tolerance,\"Negative\")\\\n",
    "                                    .when((df.Polarity>-tolerance)&(df.Polarity<tolerance),\"Neutral\")\\\n",
    "                                    .when(df.Polarity>tolerance,\"Positive\")\\\n",
    "                                    .otherwise(None)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------------+--------+--------+-----------------+\n",
      "|       id|                Text|Subjectivity|Polarity|  Target|polarity_of_users|\n",
      "+---------+--------------------+------------+--------+--------+-----------------+\n",
      "|        0|Historically ther...|        0.45|    0.35|Positive|         Positive|\n",
      "|        1|Honored and Pfize...| 0.066666667|       0| Neutral|          Neutral|\n",
      "|        2|COVID19 illuminat...|        NULL|    NULL|    NULL|             NULL|\n",
      "|Next week| our Chief Develo...|           0|       0| Neutral|          Neutral|\n",
      "|        3|Today we publishe...|           0|       0| Neutral|          Neutral|\n",
      "+---------+--------------------+------------+--------+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT *,CASE \n",
    "            WHEN Polarity<-0.0001 THEN 'Negative'\n",
    "            WHEN (Polarity>-0.0001)AND(Polarity<0.0001) THEN 'Neutral'\n",
    "            WHEN Polarity>0.0001 THEN 'Positive'\n",
    "            ELSE NULL\n",
    "        END AS polarity_of_users \n",
    "    FROM pfizer;\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    }
   ],
   "source": [
    "count_of_contain_pfizer = df.filter((df.Text.contains(\"pfizer\"))|(df.Text.contains(\"Pfizer\"))).count()\n",
    "print(count_of_contain_pfizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|  174|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(Text) AS count FROM pfizer WHERE Text ILIKE '%pfizer%';\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Text                                                                                                                                     |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|KnowTheFacts: Answers to your biggest questions about the progress of our COVID19 vaccine candidate &amp; more information on next steps.|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_count = df.select(f.max(f.length(df.Text))).alias(\"largest_text\").collect()[0][0]\n",
    "df.select(\"Text\").filter(f.length(df.Text) == char_count).orderBy(\"Text\").show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Text|\n",
      "+--------------------+\n",
      "|KnowTheFacts: Ans...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT Text FROM pfizer WHERE length(Text) = (SELECT MAX(LENGTH(Text)) FROM pfizer) ORDER BY Text LIMIT 1;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|   to|  749|\n",
      "+-----+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_without_emoji = df.withColumn(\"without_emoji\", f.regexp_replace(df.Text, r\"[^\\w\\s]\", \"\"))\n",
    "df_lower_texts = df_without_emoji.withColumn(\"lower_texts\", f.lower(df_without_emoji.without_emoji))\n",
    "df_splitted = df_lower_texts.withColumn(\"splitted\", f.split(df_lower_texts.lower_texts, \" \"))\n",
    "df_exploded = df_splitted.withColumn(\"words\", f.explode(df_splitted.splitted)).na.drop()\n",
    "word_counts = df_exploded.filter(~(df_exploded.words.isNull()|(f.trim(df_exploded.words) == \"\")))\n",
    "result = word_counts.groupBy(df_exploded[\"words\"]).count()\n",
    "result.orderBy(\"count\", ascending=False).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|   to|  764|\n",
      "+-----+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT words, COUNT(*) AS count\n",
    "    FROM (SELECT EXPLODE(SPLIT(LOWER(REGEXP_REPLACE(Text,'[^A-Za-z0-9 ]','')), ' ')) AS words FROM pfizer) AS exploded\n",
    "    WHERE words != ''\n",
    "    GROUP BY words\n",
    "    ORDER BY count DESC;\n",
    "    \"\"\"\n",
    ").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|Subjectivity|  Target|\n",
      "+------------+--------+\n",
      "|           0|Positive|\n",
      "|           0|Negative|\n",
      "|           0|Positive|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exceptions_neutral = df.select(\"Subjectivity\", \"Target\").filter((df.Subjectivity<0.01)&(df.Subjectivity>-0.01)&(df.Target!='Neutral'))\n",
    "exceptions_neutral.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default Dataset Row Count: 1076\n",
      "Cleaned Dataset Row Count: 1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "old_count = df.count()\n",
    "df = df.na.drop()\n",
    "count = df.count()\n",
    "print(f\"\"\"\n",
    "Default Dataset Row Count: {old_count}\n",
    "Cleaned Dataset Row Count: {count}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default Dataset Row Count: 1208\n",
      "Cleaned Dataset Row Count: 1208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "default_row_count = spark.sql(\"SELECT COUNT(*) AS default_row_count FROM pfizer;\").collect()[0][0]\n",
    "cleaned_row_count = spark.sql(\"SELECT COUNT(*) AS cleaned_row_count FROM pfizer WHERE COALESCE(id, Text, Subjectivity, Polarity, Target) IS NOT NULL;\").collect()[0][0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Default Dataset Row Count: {default_row_count}\n",
    "Cleaned Dataset Row Count: {cleaned_row_count}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBJECTIVITY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\"Subjectivity\", \"Target\").filter((df.Subjectivity.isNotNull())&(df.Target.isNotNull()))\n",
    "df = df.withColumn(\"Subjectivity(float)\", f.col(\"Subjectivity\").cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+\n",
      "|  Target|avg(Subjectivity(float))|\n",
      "+--------+------------------------+\n",
      "|Positive|      0.5998249713792687|\n",
      "| Neutral|     0.10404377918570272|\n",
      "|Negative|      0.4275094546637563|\n",
      "+--------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_targets = df.groupBy('Target').avg('Subjectivity(float)').alias('avg')\n",
    "all_targets.filter((df.Target == 'Positive')|(df.Target == 'Negative')|(df.Target == 'Neutral')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectivity = df.withColumn(\n",
    "    \"Objectivity\", f.when((df.Subjectivity>=0)&(df.Subjectivity<=0.33333), \"Objective\")\n",
    "                    .when((df.Subjectivity>=0.33333)&(df.Subjectivity<=0.66666), \"Half-Objective\")\n",
    "                    .otherwise(\"Subjective\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------+---------------+\n",
      "|Subjectivity|  Target|    Polarity|Polarity(float)|\n",
      "+------------+--------+------------+---------------+\n",
      "|        0.45|Positive|        0.35|           0.35|\n",
      "| 0.066666667| Neutral|           0|            0.0|\n",
      "|           0| Neutral|           0|            0.0|\n",
      "|           0| Neutral|           0|            0.0|\n",
      "|         0.3|Positive|         0.2|            0.2|\n",
      "|         0.5|Positive| 0.233333333|     0.23333333|\n",
      "| 0.316666667|Negative|-0.133333333|    -0.13333334|\n",
      "|           0| Neutral|           0|            0.0|\n",
      "|         0.9|Positive|        0.15|           0.15|\n",
      "|           0| Neutral|           0|            0.0|\n",
      "|           0| Neutral|           0|            0.0|\n",
      "|           0| Neutral|           0|            0.0|\n",
      "|           0| Neutral|           0|            0.0|\n",
      "|           0| Neutral|           0|            0.0|\n",
      "|           0| Neutral|           0|            0.0|\n",
      "+------------+--------+------------+---------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "polarity_with_nulls = df.select(\"Subjectivity\",\"Target\",\"Polarity\").withColumn(\"Polarity(float)\", f.col(\"Polarity\").cast(\"float\"))\n",
    "cleaned_polarity = polarity_with_nulls.filter((polarity_with_nulls.Subjectivity.isNotNull())&\n",
    "                                      (polarity_with_nulls.Target.isNotNull())&\n",
    "                                      (polarity_with_nulls.Polarity.isNotNull())&\n",
    "                                      (polarity_with_nulls[\"Polarity(float)\"].isNotNull()))\n",
    "polarity = cleaned_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = df.filter(df.Subjectivity>=0.66666)\n",
    "negative = df.filter((df.Subjectivity>=0)&(df.Subjectivity<=0.33333))\n",
    "neutral = df.select(\"Subjectivity\", \"Target\").filter((df.Subjectivity>0.01)&(df.Target!='Positive')&(df.Target!='Neutral'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
