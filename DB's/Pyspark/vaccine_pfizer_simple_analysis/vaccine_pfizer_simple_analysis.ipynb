{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"dataset_Vaccine_Pfizer.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"pfizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SCOPE\n",
    "\n",
    "1. Schema of the dataset.\n",
    "2. Number of tweets.\n",
    "3. Polarity of users.\n",
    "4. Count of contain pfizer.\n",
    "5. Tallest tweet.\n",
    "6. Most used word.\n",
    "7. Subjectivity of targets.\n",
    "8. Data cleaning.\n",
    "9. Relationship between Subjectivity and Polarity. <br><br><br>\n",
    "***  \n",
    "<br>\n",
    "\n",
    "- [x] Schema of the dataset.\n",
    "- [x] Number of tweets.\n",
    "- [x] Polarity of users.\n",
    "- [x] Count of contain pfizer.\n",
    "- [x] Tallest tweet.\n",
    "- [ ] Most used word.\n",
    "- [ ] Subjectivity of targets.\n",
    "- [ ] Data cleaning.\n",
    "- [ ] Relationship between Subjectivity and Polarity.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Subjectivity: string (nullable = true)\n",
      " |-- Polarity: string (nullable = true)\n",
      " |-- Target: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+\n",
      "|    col_name|data_type|comment|\n",
      "+------------+---------+-------+\n",
      "|          id|   string|   NULL|\n",
      "|        Text|   string|   NULL|\n",
      "|Subjectivity|   string|   NULL|\n",
      "|    Polarity|   string|   NULL|\n",
      "|      Target|   string|   NULL|\n",
      "+------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    DESCRIBE pfizer;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188\n"
     ]
    }
   ],
   "source": [
    "number_of_tweets = df.filter(df.Text.isNotNull()).count()\n",
    "print(number_of_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|number_of_tweets|\n",
      "+----------------+\n",
      "|            1188|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(Text) AS number_of_tweets FROM pfizer WHERE Text IS NOT NULL;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|           Polarity|\n",
      "+-------+-------------------+\n",
      "|  count|               1128|\n",
      "|   mean|0.16325622765526784|\n",
      "| stddev|0.25291704571613854|\n",
      "|    min|       -0.008333333|\n",
      "|    max|           Positive|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(\"Polarity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------------+--------+--------+-----------------+\n",
      "|       id|                Text|Subjectivity|Polarity|  Target|polarity_of_users|\n",
      "+---------+--------------------+------------+--------+--------+-----------------+\n",
      "|        0|Historically ther...|        0.45|    0.35|Positive|         Positive|\n",
      "|        1|Honored and Pfize...| 0.066666667|       0| Neutral|          Neutral|\n",
      "|        2|COVID19 illuminat...|        NULL|    NULL|    NULL|             NULL|\n",
      "|Next week| our Chief Develo...|           0|       0| Neutral|          Neutral|\n",
      "|        3|Today we publishe...|           0|       0| Neutral|          Neutral|\n",
      "+---------+--------------------+------------+--------+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tolerance = 0.0001\n",
    "df.withColumn(\"polarity_of_users\", f.when(df.Polarity<-tolerance,\"Negative\")\\\n",
    "                                    .when((df.Polarity>-tolerance)&(df.Polarity<tolerance),\"Neutral\")\\\n",
    "                                    .when(df.Polarity>tolerance,\"Positive\")\\\n",
    "                                    .otherwise(None)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------------+--------+--------+-----------------+\n",
      "|       id|                Text|Subjectivity|Polarity|  Target|polarity_of_users|\n",
      "+---------+--------------------+------------+--------+--------+-----------------+\n",
      "|        0|Historically ther...|        0.45|    0.35|Positive|         Positive|\n",
      "|        1|Honored and Pfize...| 0.066666667|       0| Neutral|          Neutral|\n",
      "|        2|COVID19 illuminat...|        NULL|    NULL|    NULL|             NULL|\n",
      "|Next week| our Chief Develo...|           0|       0| Neutral|          Neutral|\n",
      "|        3|Today we publishe...|           0|       0| Neutral|          Neutral|\n",
      "+---------+--------------------+------------+--------+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT *,CASE \n",
    "            WHEN Polarity<-0.0001 THEN 'Negative'\n",
    "            WHEN (Polarity>-0.0001)AND(Polarity<0.0001) THEN 'Neutral'\n",
    "            WHEN Polarity>0.0001 THEN 'Positive'\n",
    "            ELSE NULL\n",
    "        END AS polarity_of_users \n",
    "    FROM pfizer;\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    }
   ],
   "source": [
    "count_of_contain_pfizer = df.filter((df.Text.contains(\"pfizer\"))|(df.Text.contains(\"Pfizer\"))).count()\n",
    "print(count_of_contain_pfizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|  174|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(Text) AS count FROM pfizer WHERE Text ILIKE '%pfizer%';\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Text                                                                                                                                     |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|KnowTheFacts: Answers to your biggest questions about the progress of our COVID19 vaccine candidate &amp; more information on next steps.|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_count = df.select(f.max(f.length(df.Text))).alias(\"largest_text\").collect()[0][0]\n",
    "df.select(\"Text\").filter(f.length(df.Text) == char_count).orderBy(\"Text\").show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Text|\n",
      "+--------------------+\n",
      "|KnowTheFacts: Ans...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT Text FROM pfizer WHERE length(Text) = (SELECT MAX(LENGTH(Text)) FROM pfizer) ORDER BY Text LIMIT 1;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|   to|  749|\n",
      "+-----+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_without_emoji = df.withColumn(\"without_emoji\", f.regexp_replace(df.Text, r\"[^\\w\\s]\", \"\"))\n",
    "df_lower_texts = df_without_emoji.withColumn(\"lower_texts\", f.lower(df_without_emoji.without_emoji))\n",
    "df_splitted = df_lower_texts.withColumn(\"splitted\", f.split(df_lower_texts.lower_texts, \" \"))\n",
    "df_exploded = df_splitted.withColumn(\"words\", f.explode(df_splitted.splitted)).na.drop()\n",
    "word_counts = df_exploded.filter(~(df_exploded.words.isNull()|(f.trim(df_exploded.words) == \"\")))\n",
    "result = word_counts.groupBy(df_exploded[\"words\"]).count()\n",
    "result.orderBy(\"count\", ascending=False).show(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
